{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Regularization\n",
    "### LECTURE: The importance of equal batch sizes\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "en1pAvDIfo1f"
   },
   "outputs": [],
   "source": [
    "# Set the number of data points per cluster.\n",
    "nPerClust = 200\n",
    "\n",
    "# Create an array 'th' representing angles from 0 to 4*pi.\n",
    "th = np.linspace(0, 4*np.pi, nPerClust)\n",
    "\n",
    "# Set radii for two clusters.\n",
    "r1 = 10\n",
    "r2 = 15\n",
    "\n",
    "# Generate data for the first cluster 'a'.\n",
    "a = [r1*np.cos(th) + np.random.randn(nPerClust)*3,\n",
    "     r1*np.sin(th) + np.random.randn(nPerClust)]\n",
    "\n",
    "# Generate data for the second cluster 'b'.\n",
    "b = [r2*np.cos(th) + np.random.randn(nPerClust),\n",
    "     r2*np.sin(th) + np.random.randn(nPerClust)*3]\n",
    "\n",
    "# Create true labels. '0' for the first cluster, '1' for the second.\n",
    "labels_np = np.vstack((np.zeros((nPerClust, 1)), np.ones((nPerClust, 1))))\n",
    "\n",
    "# Concatenate 'a' and 'b' data into a single matrix 'data_np'.\n",
    "data_np = np.hstack((a, b)).T\n",
    "\n",
    "# Convert 'data_np' and 'labels_np' into PyTorch tensors.\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).float()\n",
    "\n",
    "# Visualize the data.\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.plot(data[np.where(labels==0)[0], 0], data[np.where(labels==0)[0], 1], 'bs')\n",
    "plt.plot(data[np.where(labels==1)[0], 0], data[np.where(labels==1)[0], 1], 'ko')\n",
    "plt.title(\"The qwerties' doughnuts!\")\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-GvjKA8AesK"
   },
   "source": [
    "# Separate the data into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVrlOHYIAg0r"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets using scikit-learn's train_test_split function.\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=.1)\n",
    "\n",
    "# Convert the training and testing data and labels into PyTorch TensorDatasets.\n",
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data  = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# Define batch sizes for the data loaders.\n",
    "# 'train_batchsize' is the batch size for training, and 'test_batchsize' is for testing.\n",
    "train_batchsize = 16\n",
    "test_batchsize  = test_data.tensors[0].shape[0] - 2  # Set test batch size slightly smaller for demonstration purposes.\n",
    "\n",
    "# Create DataLoader objects for training and testing data.\n",
    "# - 'train_loader' will shuffle the training data and drop the last batch if its size is less than 'train_batchsize'.\n",
    "# - 'test_loader' will use 'test_batchsize' for testing.\n",
    "train_loader = DataLoader(train_data, batch_size=train_batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=test_batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMP8h16StbgK"
   },
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in test_loader:\n",
    "  print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx2OI7PgQ9xx"
   },
   "source": [
    "# Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0qe1q9nRwPG"
   },
   "outputs": [],
   "source": [
    "# Define a custom neural network class named 'theModelClass' that inherits from nn.Module.\n",
    "class theModelClass(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### layers\n",
    "    # Define the layers of the neural network:\n",
    "    # - 'input': Linear layer with input size 2 and output size 128.\n",
    "    # - 'hidden': Linear layer with input size 128 and output size 128.\n",
    "    # - 'output': Linear layer with input size 128 and output size 1.\n",
    "    self.input  = nn.Linear(2, 128)\n",
    "    self.hidden = nn.Linear(128, 128)\n",
    "    self.output = nn.Linear(128, 1)\n",
    "\n",
    "  # Define the forward pass of the neural network.\n",
    "  def forward(self, x):\n",
    "    # Apply the ReLU activation function to the output of the 'input' layer.\n",
    "    x = F.relu(self.input(x))\n",
    "    \n",
    "    # Apply the ReLU activation function to the output of the 'hidden' layer.\n",
    "    x = F.relu(self.hidden(x))\n",
    "    \n",
    "    # The final output is obtained from the 'output' layer without an activation function.\n",
    "    x = self.output(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0JMIGb1iV_9"
   },
   "outputs": [],
   "source": [
    "# Define a function named 'createANewModel' that creates an instance of the custom neural network model, sets the loss function, and optimizer.\n",
    "\n",
    "def createANewModel():\n",
    "  # Create an instance of the custom neural network model 'theModelClass' that you defined earlier.\n",
    "  ANNQC = theModelClass()\n",
    "\n",
    "  # Define the loss function as Binary Cross-Entropy with Logits Loss.\n",
    "  # This loss function is suitable for binary classification tasks.\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  # Define the optimizer for training the neural network.\n",
    "  # Here, Stochastic Gradient Descent (SGD) optimizer is used with a learning rate of 0.01.\n",
    "  optimizer = torch.optim.SGD(ANNQC.parameters(), lr=0.01)\n",
    "\n",
    "  # Return the created neural network, loss function, and optimizer.\n",
    "  return ANNQC, lossfun, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVD1nFTli7TO"
   },
   "outputs": [],
   "source": [
    "# Define a global parameter 'numepochs' which represents the number of training epochs.\n",
    "# In this case, it's set to 500.\n",
    "\n",
    "# Define a function named 'trainTheModel' that trains the neural network model.\n",
    "# This function takes three inputs: 'ANNQC' (the model), 'lossfun' (the loss function), and 'optimizer' (the optimizer).\n",
    "\n",
    "def trainTheModel(ANNQC, lossfun, optimizer):\n",
    "  # Initialize lists to store training and test accuracies for each epoch.\n",
    "  trainAcc = []  # Training accuracies\n",
    "  testAcc = []   # Test accuracies\n",
    "\n",
    "  # Loop over training epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # Initialize a list to store batch accuracies for each batch within an epoch.\n",
    "    batchAcc = []\n",
    "\n",
    "    # Loop over training data batches using 'train_loader'\n",
    "    for X, y in train_loader:\n",
    "\n",
    "      # Forward pass: compute predictions 'yHat' and calculate the loss using 'lossfun'.\n",
    "      yHat = ANNQC(X)\n",
    "      loss = lossfun(yHat, y)\n",
    "\n",
    "      # Backpropagation: zero gradients, calculate gradients, and update model parameters using 'optimizer'.\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Compute training accuracy for the current batch and append it to 'batchAcc'.\n",
    "      # Here, we check if predictions 'yHat' are greater than 0, assuming a binary classification task.\n",
    "      batchAcc.append(100 * torch.mean(((yHat > 0) == y).float()).item())\n",
    "    # End of batch loop...\n",
    "\n",
    "    # Calculate the average training accuracy for the current epoch and append it to 'trainAcc'.\n",
    "    trainAcc.append(np.mean(batchAcc))\n",
    "\n",
    "    # Test accuracy (NOTE: testing in batches!)\n",
    "    tstacc = []\n",
    "\n",
    "    # Loop over test data batches using 'test_loader'\n",
    "    for X, y in test_loader:\n",
    "\n",
    "      # Forward pass: compute predictions 'yHat' for the test batch.\n",
    "      yHat = ANNQC(X)\n",
    "\n",
    "      # Compute test accuracy for the current batch and append it to 'tstacc'.\n",
    "      tstacc.append(100 * torch.mean(((yHat > 0) == y).float()).item())\n",
    "\n",
    "    # Calculate the average test accuracy for the current epoch and append it to 'testAcc'.\n",
    "    testAcc.append(np.mean(tstacc))\n",
    "  \n",
    "  # Function output: Return the lists of training and test accuracies.\n",
    "  return trainAcc, testAcc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FHXO7mRRCMg"
   },
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXku7xIdcu7Y"
   },
   "outputs": [],
   "source": [
    "# Create a new neural network model, loss function, and optimizer using the 'createANewModel' function.\n",
    "# 'createANewModel' returns three values: the model ('ANNQC'), loss function ('lossfun'), and optimizer ('optimizer').\n",
    "\n",
    "# Create the model architecture, loss function, and optimizer.\n",
    "ANNQC, lossfun, optimizer = createANewModel()\n",
    "\n",
    "# Train the model using the 'trainTheModel' function.\n",
    "# Pass the model ('ANNQC'), loss function ('lossfun'), and optimizer ('optimizer') as inputs to the function.\n",
    "\n",
    "# The function returns two lists: 'trainAcc' (training accuracies) and 'testAcc' (test accuracies).\n",
    "trainAcc, testAcc = trainTheModel(ANNQC, lossfun, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYouZAY4i3jM"
   },
   "outputs": [],
   "source": [
    "# Create a new figure for plotting with a specified size (10 units in width and 5 units in height).\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot the training accuracies as blue squares ('bs').\n",
    "plt.plot(trainAcc,'bs')\n",
    "\n",
    "# Plot the test accuracies as red circles ('ro').\n",
    "plt.plot(testAcc,'ro')\n",
    "\n",
    "# Set the x-axis label to 'Epochs'.\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "# Set the y-axis label to 'Accuracy (%)'.\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "# Create a legend for the plot, labeling the blue squares as 'Train' and the red circles as 'Test'.\n",
    "plt.legend(['Train','Test'])\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVXa_1zZkvbm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBTDJBbZvRh0ehhvC0ofhn",
   "collapsed_sections": [],
   "name": "DUDL_regular_testBatchT2.ipynb",
   "provenance": [
    {
     "file_id": "15mfK6oci_9838ULajZ5JwriIMRFRlhRx",
     "timestamp": 1618576737121
    },
    {
     "file_id": "17KCLWj5_rIPAJqSQ1dJFAkSrJ7ctDwne",
     "timestamp": 1616945891013
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1616941708388
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
