{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for the task.\n",
    "import torch  # Import PyTorch for deep learning.\n",
    "import torch.nn as nn  # Import the neural network module from PyTorch.\n",
    "import numpy as np  # Import NumPy for numerical operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "outputs": [],
   "source": [
    "# Load the Iris dataset using Seaborn.\n",
    "import seaborn as sns\n",
    "iris_data = sns.load_dataset('iris')\n",
    "\n",
    "# Convert the dataset from a pandas dataframe to a PyTorch tensor.\n",
    "data = torch.tensor(iris_data[iris_data.columns[0:4]].values).float()\n",
    "\n",
    "# Transform the species labels into numerical values.\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "labels[iris_data.species == 'versicolor'] = 1\n",
    "labels[iris_data.species == 'virginica'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([50, 50, 50]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiAFAHB20DQc"
   },
   "source": [
    "# Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mwhgV43SXbCN"
   },
   "outputs": [],
   "source": [
    "# Set the proportion of data for training (e.g., 80% for training).\n",
    "training_proportion = 0.8\n",
    "\n",
    "# Calculate the number of training examples based on the proportion.\n",
    "num_training = int(len(labels) * training_proportion)\n",
    "\n",
    "# Initialize a boolean vector to select data and labels for training.\n",
    "train_test_bool = np.zeros(len(labels), dtype=bool)\n",
    "\n",
    "# Randomly select samples for training.\n",
    "train_indices = np.random.choice(range(len(labels)), num_training, replace=False)\n",
    "train_test_bool[train_indices] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True, False, False, False,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LPcj_f92bYs0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of full dataset:\n",
      "tensor(1.)\n",
      " \n",
      "Average of training dataset:\n",
      "tensor(0.9750)\n",
      " \n",
      "Average of testing dataset:\n",
      "tensor(1.1000)\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of species labels in the dataset.\n",
    "print('Average of full dataset:')\n",
    "print(torch.mean(labels.float()))  # Should be 1 by definition\n",
    "print(' ')\n",
    "\n",
    "print('Average of training dataset:')\n",
    "print(torch.mean(labels[train_test_bool].float()))  # Should also be 1\n",
    "print(' ')\n",
    "\n",
    "print('Average of testing dataset:')\n",
    "print(torch.mean(labels[~train_test_bool].float()))  # Should also be 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v0JMIGb1iV_9"
   },
   "outputs": [],
   "source": [
    "# Define the architecture of the artificial neural network (ANN) model.\n",
    "custom_ann_model = nn.Sequential(\n",
    "    nn.Linear(4, 64),   # Input layer\n",
    "    nn.ReLU(),          # ReLU activation\n",
    "    nn.Linear(64, 64),  # Hidden layer\n",
    "    nn.ReLU(),          # ReLU activation\n",
    "    nn.Linear(64, 3)    # Output layer\n",
    ")\n",
    "\n",
    "# Define the loss function (Cross-Entropy Loss).\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent).\n",
    "optimizer = torch.optim.SGD(custom_ann_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iyxr6_P9b-x5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the entire dataset:\n",
      "torch.Size([150, 4])\n",
      "Shape of the training set:\n",
      "torch.Size([120, 4])\n",
      "Shape of the test set:\n",
      "torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the entire dataset, training set, and test set.\n",
    "print('Shape of the entire dataset:')\n",
    "print(data.shape)\n",
    "\n",
    "print('Shape of the training set:')\n",
    "print(data[train_test_bool, :].shape)\n",
    "\n",
    "print('Shape of the test set:')\n",
    "print(data[~train_test_bool, :].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbx3Zkc_0UT8"
   },
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cVD1nFTli7TO"
   },
   "outputs": [],
   "source": [
    "# Set the number of training epochs.\n",
    "num_epochs = 1000\n",
    "\n",
    "# Initialize losses and ongoing accuracy.\n",
    "losses = torch.zeros(num_epochs)\n",
    "ongoing_accuracy = []\n",
    "\n",
    "# Loop over epochs for training.\n",
    "for epoch_idx in range(num_epochs):\n",
    "\n",
    "    # Forward pass through the model using the training data.\n",
    "    predictions = custom_ann_model(data[train_test_bool, :])\n",
    "\n",
    "    # Compute accuracy for the current epoch.\n",
    "    epoch_accuracy = 100 * torch.mean(\n",
    "        (torch.argmax(predictions, axis=1) == labels[train_test_bool]).float())\n",
    "    ongoing_accuracy.append(epoch_accuracy)\n",
    "\n",
    "    # Compute the Cross-Entropy loss.\n",
    "    loss = loss_function(predictions, labels[train_test_bool])\n",
    "    losses[epoch_idx] = loss\n",
    "\n",
    "    # Backpropagation.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vXku7xIdcu7Y"
   },
   "outputs": [],
   "source": [
    "# Final forward pass using the training data.\n",
    "train_predictions = custom_ann_model(data[train_test_bool, :])\n",
    "training_accuracy = 100 * torch.mean(\n",
    "    (torch.argmax(train_predictions, axis=1) == labels[train_test_bool]).float())\n",
    "\n",
    "# Final forward pass using the test data.\n",
    "test_predictions = custom_ann_model(data[~train_test_bool, :])\n",
    "testing_accuracy = 100 * torch.mean(\n",
    "    (torch.argmax(test_predictions, axis=1) == labels[~train_test_bool]).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JYouZAY4i3jM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TRAIN accuracy: 99.1667%\n",
      "Final TEST accuracy:  96.6667%\n"
     ]
    }
   ],
   "source": [
    "# Report the final training and testing accuracies.\n",
    "print('Final TRAIN accuracy: %g%%' % training_accuracy)\n",
    "print('Final TEST accuracy:  %g%%' % testing_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcbD9nZmd9nu"
   },
   "outputs": [],
   "source": [
    "# normally also inspect losses and accuracy by epoch, etc etc etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAzQqbq8fqSt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwTbABK7fqzZ"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWC_SDDCfrAo"
   },
   "outputs": [],
   "source": [
    "# 1) Randomly assigning data samples to be in the train vs test phase produced a statistical balance, but it was \n",
    "#    not perfect. Write an algorithm that will guarantee a balance of flower types while also randomly assigning\n",
    "#    samples to be in train vs. test.\n",
    "# \n",
    "# 2) Revert the code to its original form -- with the strong imbalance in flower types. Then train the model. What are\n",
    "#    the train and test accuracies? Compute the accuracy separately for each type of flower to see whether the model\n",
    "#    learned some categories, or whether it performed equally on all three categories. Are you surprised at the results? \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width     species\n",
       "15           5.7          4.4           1.5          0.4      setosa\n",
       "2            4.7          3.2           1.3          0.2      setosa\n",
       "68           6.2          2.2           4.5          1.5  versicolor\n",
       "37           4.9          3.6           1.4          0.1      setosa\n",
       "65           6.7          3.1           4.4          1.4  versicolor"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle data to induce randomness\n",
    "shuffled_data = iris_data.sample(frac=1, random_state=740)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "train_list = []\n",
    "test_list = []\n",
    "train_size = 0.8\n",
    "\n",
    "for label in shuffled_data['species'].unique():\n",
    "    # Get subset of dataframe of one label\n",
    "    label_subset = shuffled_data[shuffled_data['species'] == label]\n",
    "\n",
    "    # Find index to split dataframe on\n",
    "    split_idx = int(len(label_subset) * train_size)\n",
    "\n",
    "    # Append the subsets to the lists\n",
    "    train_list.append(label_subset.iloc[:split_idx])\n",
    "    test_list.append(label_subset.iloc[split_idx:])\n",
    "\n",
    "# Concat the lists into dataframes, then shuffle to randomize\n",
    "train_df = pd.concat(train_list).sample(frac=1, random_state=740).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).sample(frac=1, random_state=740).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "setosa        40\n",
       "versicolor    40\n",
       "virginica     40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "versicolor    10\n",
       "virginica     10\n",
       "setosa        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = torch.argmax(train_predictions, dim=1)\n",
    "test_preds = torch.argmax(test_predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[train_test_bool]\n",
    "labels[~train_test_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Class 0': np.float64(1.0),\n",
       " 'Class 1': np.float64(0.972972972972973),\n",
       " 'Class 2': np.float64(1.0)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(iris_data['species'].unique())\n",
    "correct_counts = np.zeros(num_classes)\n",
    "total_counts = np.zeros(num_classes)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    correct_counts[i] += ((train_preds == labels[train_test_bool]) & (labels[train_test_bool] == i)).sum().item()\n",
    "    total_counts[i] += (labels[train_test_bool] == i).sum().item()\n",
    "\n",
    "class_train_accuracies = {f'Class {i}': correct_counts[i] / total_counts[i] if total_counts[i] > 0 else 0 for i in range(num_classes)}\n",
    "class_train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Class 0': np.float64(1.0),\n",
       " 'Class 1': np.float64(0.9230769230769231),\n",
       " 'Class 2': np.float64(1.0)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(iris_data['species'].unique())\n",
    "correct_counts = np.zeros(num_classes)\n",
    "total_counts = np.zeros(num_classes)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    correct_counts[i] += ((test_preds == labels[~train_test_bool]) & (labels[~train_test_bool] == i)).sum().item()\n",
    "    total_counts[i] += (labels[~train_test_bool] == i).sum().item()\n",
    "\n",
    "class_train_accuracies = {f'Class {i}': correct_counts[i] / total_counts[i] if total_counts[i] > 0 else 0 for i in range(num_classes)}\n",
    "class_train_accuracies"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNk9aAiPToKpfieCvxrzbDR",
   "collapsed_sections": [],
   "name": "DUDL_overfitting_manual.ipynb",
   "provenance": [
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "ME740",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
